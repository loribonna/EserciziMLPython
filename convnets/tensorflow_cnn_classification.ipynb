{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow_cnn_classification.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"aIGLh3TCs2Nh","colab_type":"text"},"cell_type":"markdown","source":["These lines are for making tensorboard visualization work within the iPython notebook environment. "]},{"metadata":{"id":"sKH-RqGoLJgT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","! unzip -o ngrok-stable-linux-amd64.zip\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","# Start Tensorboard server\n","LOG_DIR = '/tmp/logs'\n","get_ipython().system_raw('rm -rf {}'.format(LOG_DIR))\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AMzwqLJitKib","colab_type":"text"},"cell_type":"markdown","source":["Print the public url in which we can find tensorboard."]},{"metadata":{"id":"0OxWmGhkLrvx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! curl -s http://localhost:4040/api/tunnels | python -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xsCpyQCutY8_","colab_type":"text"},"cell_type":"markdown","source":["Import packages as usual."]},{"metadata":{"id":"VpkTan6YJZVu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","from os.path import join"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3a7Fv_uataco","colab_type":"text"},"cell_type":"markdown","source":["Helper functions for data loading (MNIST)."]},{"metadata":{"id":"IAi9Jr1qJj3J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_mnist_data(download_data_path, one_hot=True, verbose=False):\n","    \"\"\"\n","\n","    Parameters\n","    ----------\n","    download_data_path : string\n","        Directory where MNIST data are downloaded and extracted.\n","    one_hot : bool\n","        If True, targets are returned into one-hot format\n","    verbose : bool\n","        If True, print dataset tensors dimensions\n","\n","    Returns\n","    -------\n","    mnist : Dataset\n","        Structure containing train, val and test mnist dataset in a friendly format.\n","    \"\"\"\n","\n","    # Download and read in MNIST dataset\n","    mnist = input_data.read_data_sets(download_data_path, one_hot=one_hot)\n","\n","    if verbose:\n","\n","        # Print image tensors shapes\n","        print('TRAIN tensor shape: {}'.format(mnist.train.images.shape))\n","        print('VAL   tensor shape: {}'.format(mnist.validation.images.shape))\n","        print('TEST  tensor shape: {}'.format(mnist.test.images.shape))\n","\n","        # Print labels shape (encoded as one-hot vectors)\n","        print('TRAIN labels shape: {}'.format(mnist.train.labels.shape))\n","        print('VAL   labels shape: {}'.format(mnist.validation.labels.shape))\n","        print('TEST  labels shape: {}'.format(mnist.test.labels.shape))\n","\n","    return mnist"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XsDlQ9xYti0L","colab_type":"text"},"cell_type":"markdown","source":["Our magic epsilon for cross-entropy loss regularization."]},{"metadata":{"id":"B_QkyV-vJmtB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["epsilon = np.finfo(np.float32).eps"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rEXw8C3mtpEZ","colab_type":"text"},"cell_type":"markdown","source":["A ConvNet model, it takes placeholder and other information in the constructor. Your job is to implement the four make_* functions, as usual, defining the graph for inference, the loss, the training step and the accuracy. Useful tensorflow API functions: [tf.reshape](https://www.tensorflow.org/api_docs/python/tf/reshape), [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), [tf.nn.relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu), [tf.layers.dropout](https://www.tensorflow.org/api_docs/python/tf/layers/dropout), [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)"]},{"metadata":{"id":"XQcL4BagJpNh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class TinyConvnet:\n","\n","    def __init__(self, x, targets, training, n_classes, data_shape):\n","        \"\"\"\n","        x: placeholder for input data\n","        targets: placeholder for labels\n","        training: placeholder for training phase (bool)\n","        n_classes: integer\n","        data_shape: tuple (28, 28, 1)\n","        \"\"\"\n","\n","        self.x = x\n","        self.targets = targets\n","        self.training = training\n","        self.n_classes = n_classes\n","        self.data_shape = data_shape\n","\n","        self.inference = None\n","        self.loss = None\n","        self.train_step = None\n","        self.accuracy = None\n","\n","        self.make_inference()\n","        self.make_loss()\n","        self.make_train_step()\n","        self.make_accuracy()\n","\n","    def make_inference(self):\n","\n","        h, w, c = self.data_shape\n","\n","        # Reshape flattened input into images\n","        x = ...\n","        \n","        # Apply a 3x3 convolution with 32 filters, relu activated and followed by a 2x2 max-pooling \n","        ...\n","        \n","        \n","        # Apply a 3x3 convolution with 64 filters, relu activated and followed by a 2x2 max-pooling \n","        ...\n","        \n","        # Flatten out the activation map\n","        ...\n","        \n","        # Apply dropout\n","        ...\n","        \n","        # Final classification fully connected layer\n","        self.inference = ...\n","\n","    def make_loss(self):\n","        # Make crossentropy loss\n","        self.loss = ...\n","\n","    def make_train_step(self):\n","        self.train_step = ...\n","\n","    def make_accuracy(self):\n","        # make accuracy, using tf.argmax, tf.equal, tf.cast, tf.reduce_mean\n","        self.accuracy = ..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"8azpthHlvjIy","colab_type":"text"},"cell_type":"markdown","source":["Some parameters..."]},{"metadata":{"id":"teHxYcKRJsE5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# MNIST parameters\n","n_classes = 10\n","h, w, c = 28, 28, 1\n","\n","# Training parameters\n","training_epochs = 10\n","batch_size = 128"],"execution_count":0,"outputs":[]},{"metadata":{"id":"amGjIbBKvn8c","colab_type":"text"},"cell_type":"markdown","source":["Get the MNIST dataset."]},{"metadata":{"id":"ZACoIBg6Jtpa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Load MNIST data\n","mnist = get_mnist_data('/tmp/mnist', verbose=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KaJaLURKvrbf","colab_type":"text"},"cell_type":"markdown","source":["Define placeholders. As usual, define for each placeholder shapes and dtype."]},{"metadata":{"id":"skM80kVoJxCR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Placeholders\n","x = ...\n","targets = ...\n","training = ..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kr1rgTt7vxaj","colab_type":"text"},"cell_type":"markdown","source":["Instantiate a TinyConvnet model."]},{"metadata":{"id":"wAp4EwlyJzFx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define model\n","model = TinyConvnet(x, targets, training, n_classes, data_shape=(h, w, c))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"phZhFDsgv32u","colab_type":"text"},"cell_type":"markdown","source":["This is how you define summaries to be logged for tensorboard visualization. Summaries are then evaluated within the session as graph nodes and provided to a SummaryWriter (see below)."]},{"metadata":{"id":"JYTsJHvDJ1np","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Loss summary\n","merged_train = tf.summary.merge([tf.summary.scalar('Loss', model.loss)])\n","train_writer = tf.summary.FileWriter(join(LOG_DIR, 'train'))\n","train_steps = 0\n","\n","# Accuracy summary\n","merget_val = tf.summary.merge([tf.summary.scalar('Accuracy', model.accuracy)])\n","val_writer = tf.summary.FileWriter(join(LOG_DIR, 'val'))\n","val_steps = 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M08tYX6HweQ5","colab_type":"text"},"cell_type":"markdown","source":["Start session and initialize variables."]},{"metadata":{"id":"yO3cHCJXJ4eL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["sess = tf.Session()\n","\n","# Initialize all variables\n","sess.run(tf.global_variables_initializer())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EurTHnZ5whyE","colab_type":"text"},"cell_type":"markdown","source":["Training loop! Now with summaries!"]},{"metadata":{"id":"s-4FuJ0AJ8ZZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Number of batches to process to see whole dataset\n","batches_each_epoch = mnist.train.num_examples // batch_size\n","\n","for epoch in range(training_epochs):\n","\n","    # During training measure accuracy on validation set to have an idea of what's happening\n","    val_accuracy, summary = ...\n","    val_writer.add_summary(summary, global_step=val_steps)\n","    val_steps += 1\n","\n","    print('Epoch: {:06d} - VAL accuracy: {:.03f}'.format(epoch, val_accuracy))\n","\n","    for _ in range(batches_each_epoch):\n","\n","        # Load a batch of training data\n","        x_batch, target_batch = mnist.train.next_batch(batch_size)\n","\n","        # Actually run one training step here, and compute summaries for train\n","        _, summary = ...\n","        \n","        train_writer.add_summary(summary, global_step=train_steps)\n","        train_steps += 1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GndOKYYhw1MX","colab_type":"text"},"cell_type":"markdown","source":["Test."]},{"metadata":{"id":"Z5tMJsNiJ-9h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Eventually evaluate on whole test set when training ends\n","average_test_accuracy = 0.0\n","num_test_batches = mnist.test.num_examples // batch_size\n","for _ in range(num_test_batches):\n","    x_batch, target_batch = mnist.test.next_batch(batch_size)\n","    \n","    # Compute batch accuracy\n","    average_test_accuracy += ...\n","    \n","average_test_accuracy /= num_test_batches\n","print('*' * 50)\n","print('Training ended. TEST accuracy: {:.03f}'.format(average_test_accuracy))"],"execution_count":0,"outputs":[]}]}