{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow_cnn_segmentation.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"gHY1Ql6XGqaV","colab_type":"text"},"cell_type":"markdown","source":["These lines are for making tensorboard visualization work within the iPython notebook environment. "]},{"metadata":{"id":"B0ij8mXS1tQ1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","! unzip -o ngrok-stable-linux-amd64.zip\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","# Start Tensorboard server\n","LOG_DIR = '/tmp/logs'\n","get_ipython().system_raw('rm -rf {}'.format(LOG_DIR))\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gp_O7spqGune","colab_type":"text"},"cell_type":"markdown","source":["Print the public url in which we can find tensorboard."]},{"metadata":{"id":"4DviKpvN1xzi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! curl -s http://localhost:4040/api/tunnels | python -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vm4D9ODqOEBe","colab_type":"text"},"cell_type":"markdown","source":["Install googledrivedownloader."]},{"metadata":{"id":"eTjKoVkNCOc8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install googledrivedownloader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1A8DswRWG2_V","colab_type":"text"},"cell_type":"markdown","source":["Import packages as usual, download the dataset."]},{"metadata":{"id":"EaUg0M6OCE1n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import cv2\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","import os.path as path\n","from time import time\n","\n","from google_drive_downloader import GoogleDriveDownloader\n","\n","# Download tiles data\n","GoogleDriveDownloader.download_file_from_google_drive(file_id='1W58D4qVZtUAFprDdoC9KRyBWT0k0ie5r',\n","                                                      dest_path='./tiles.zip',\n","                                                      overwrite=True,\n","                                                      unzip=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yYfkwkyGIS7W","colab_type":"text"},"cell_type":"markdown","source":["This class models the Tiles dataset for segmentation of images. Once instantiated, use its members train_x, train_y, validation_x, validation_y, test_x, test_y."]},{"metadata":{"id":"Dk5jBqRnCNC2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class TilesDataset:\n","\n","    def __init__(self, dataset_root):\n","\n","        self.dataset_root = dataset_root\n","\n","        # Store locations of train, val and test directories\n","        self.train_x_dir      = path.join(dataset_root, 'X_train')\n","        self.train_y_dir      = path.join(dataset_root, 'Y_train')\n","        self.validation_x_dir = path.join(dataset_root, 'X_validation')\n","        self.validation_y_dir = path.join(dataset_root, 'Y_validation')\n","        self.test_x_dir       = path.join(dataset_root, 'X_test')\n","        self.test_y_dir       = path.join(dataset_root, 'Y_test')\n","\n","        # Number of dataset examples\n","        self.train_num_examples      = 10000\n","        self.validation_num_examples = 1000\n","        self.test_num_examples       = 1000\n","\n","        # Initialize empty structures to contain data\n","        self.train_x      = []\n","        self.train_y      = []\n","        self.validation_x = []\n","        self.validation_y = []\n","        self.test_x       = []\n","        self.test_y       = []\n","\n","        # Load images from `dataset_root`\n","        self._fill_data_arrays()\n","\n","    def _fill_data_arrays(self):\n","\n","        # Load training images\n","        for i in range(1, self.train_num_examples + 1):\n","            print('Loading training examples. {} / {}...'.format(i, self.train_num_examples))\n","            x_image = cv2.imread(path.join(self.train_x_dir, '{:05d}.png'.format(i)))\n","            y_image = cv2.imread(path.join(self.train_y_dir, '{:05d}.png'.format(i)), cv2.IMREAD_GRAYSCALE)\n","            self.train_x.append(x_image.astype(np.float32))\n","            self.train_y.append(np.expand_dims(y_image.astype(np.float32), 2))\n","\n","        # Load validation examples\n","        for i in range(1, self.validation_num_examples + 1):\n","            print('Loading validation examples. {} / {}...'.format(i, self.validation_num_examples))\n","            x_image = cv2.imread(path.join(self.validation_x_dir, '{:05d}.png'.format(i)))\n","            y_image = cv2.imread(path.join(self.validation_y_dir, '{:05d}.png'.format(i)), cv2.IMREAD_GRAYSCALE)\n","            self.validation_x.append(x_image.astype(np.float32))\n","            self.validation_y.append(np.expand_dims(y_image.astype(np.float32), 2))\n","\n","        # Load test examples\n","        for i in range(1, self.test_num_examples + 1):\n","            print('Loading test examples. {} / {}...'.format(i, self.test_num_examples))\n","            x_image = cv2.imread(path.join(self.test_x_dir, '{:05d}.png'.format(i)))\n","            y_image = cv2.imread(path.join(self.test_y_dir, '{:05d}.png'.format(i)), cv2.IMREAD_GRAYSCALE)\n","            self.test_x.append(x_image.astype(np.float32))\n","            self.test_y.append(np.expand_dims(y_image.astype(np.float32), 2))\n","\n","    def dump_to_file(self, file_path, protocol=pickle.HIGHEST_PROTOCOL):\n","        with open(file_path, 'wb') as f:\n","            pickle.dump(self, f, protocol=protocol)\n","\n","\n","def convert_target_to_one_hot(target_batch):\n","    \"\"\"\n","    Convert a batch of targets from (height,width,1) to (height,width,2) one-hot encoding.\n","    \"\"\"\n","    b, h, w, c = target_batch.shape\n","    out_tensor = np.zeros(shape=(b, h, w, 2))\n","    for k, cur_example in enumerate(target_batch):\n","        foreground_mask = np.squeeze(cur_example > 0)\n","        background_mask = np.squeeze(cur_example == 0)\n","        out_tensor[k, background_mask, 0] = 1.0\n","        out_tensor[k, foreground_mask, 1] = 1.0\n","    return out_tensor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BiapFCjKJwsT","colab_type":"text"},"cell_type":"markdown","source":["This class implements the deep model for tiles segmentation. Implement all make_* methods (except for summaries)."]},{"metadata":{"id":"pKK4A9oKCmRV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class TileSegmenter:\n","\n","    def __init__(self, x, targets, data_shape):\n","\n","        self.x = x\n","        self.targets = targets\n","        self.data_shape = data_shape\n","\n","        self.inference = None\n","        self.loss = None\n","        self.train_step = None\n","        self.summaries = None\n","\n","        self.make_inference()\n","        self.make_loss()\n","        self.make_train_step()\n","        self.make_summaries()\n","\n","    def make_inference(self):\n","      \n","        # Use 2D conv with strides. Stack enough layers to reduce dimensions a bit, \n","        # then upsample using tf.image.resize_bilinear, then apply a final conv to reach 2\n","        # channel outputs.\n","        \n","        self.inference = ...\n","\n","    def make_loss(self):\n","        # Define loss function\n","        self.loss = ...\n","\n","    def make_train_step(self):\n","        self.train_step = ...\n","\n","    def make_summaries(self):\n","        \n","        # Add TensorBoard Summaries\n","        how_many_images = 3\n","\n","        # --- scalar summaries\n","        tf.summary.scalar('loss', self.loss)\n","        tf.summary.image('input', self.x, max_outputs=how_many_images)\n","\n","        # --- foreground image summaries\n","        fg_target_image = tf.expand_dims(tf.gather(tf.transpose(self.targets, [3, 0, 1, 2]), 1), axis=3)\n","        fg_pred_image = tf.expand_dims(tf.gather(tf.transpose(self.inference, [3, 0, 1, 2]), 1), axis=3)\n","        fg_pred_image_rounded = tf.round(tf.nn.softmax(self.inference, dim=3))\n","        fg_pred_image_rounded = tf.expand_dims(tf.gather(tf.transpose(fg_pred_image_rounded, [3, 0, 1, 2]), 1), axis=3)\n","\n","        tf.summary.image('FOREGROUND_(targets)', fg_target_image, max_outputs=how_many_images)\n","        tf.summary.image('FOREGROUND_(prediction)', fg_pred_image, max_outputs=how_many_images)\n","        tf.summary.image('FOREGROUND_ROUNDED_(prediction)', fg_pred_image_rounded, max_outputs=how_many_images)\n","\n","        # --- merge all summaries and initialize the summary writer\n","        self.summaries = tf.summary.merge_all()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RoF4f3ItLvWI","colab_type":"text"},"cell_type":"markdown","source":["Some parameters..."]},{"metadata":{"id":"920WDCJmDNoa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Training parameters\n","h, w, c = 64, 64, 3\n","training_epochs = 1000\n","batch_size = 64"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GR5myAGmLxKJ","colab_type":"text"},"cell_type":"markdown","source":["Instantiate the dataset..."]},{"metadata":{"id":"4u3viXOJCziE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Load tiles dataset\n","tiles_dataset = TilesDataset(dataset_root='./toy_dataset_tiles')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BAsH8Q4vL0Iv","colab_type":"text"},"cell_type":"markdown","source":["Placeholders"]},{"metadata":{"id":"2KkvX-fHC22p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Placeholders\n","x = ...\n","targets = ..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"nm2boNYcL2LC","colab_type":"text"},"cell_type":"markdown","source":["Instantiate the model"]},{"metadata":{"id":"tnTjpsFZC7HE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Define model\n","model = TileSegmenter(x, targets, data_shape=(h, w, c))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L-vH9EskL5mI","colab_type":"text"},"cell_type":"markdown","source":["Start session and initialize variables."]},{"metadata":{"id":"q6b1dud0DS5q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["sess = tf.Session()\n","        \n","# Initialize all variables\n","sess.run(tf.global_variables_initializer())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X0ShZkQFMYbV","colab_type":"text"},"cell_type":"markdown","source":["Set up the writer for tensorboard logs."]},{"metadata":{"id":"5vMJRFXJDgGi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# FileWriter to save Tensorboard summary\n","train_writer = tf.summary.FileWriter(LOG_DIR, graph=sess.graph)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eVqZzm_PMvQh","colab_type":"text"},"cell_type":"markdown","source":["Training loop, with summaries!"]},{"metadata":{"id":"5tVpMTsxDjuz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Number of batches to process to see whole dataset\n","batches_each_epoch = tiles_dataset.train_num_examples // batch_size\n","\n","for epoch in range(training_epochs):\n","\n","    epoch_loss = 0.0\n","\n","    idx_start = 0\n","    for _ in range(batches_each_epoch):\n","\n","        idx_end = idx_start + batch_size\n","\n","        # Load a batch of training data\n","        x_batch = np.array(tiles_dataset.train_x[idx_start:idx_end])\n","        target_batch = np.array(tiles_dataset.train_y[idx_start:idx_end])\n","\n","        # Convert the target batch into one-hot encoding (from 64x64x1 to 64x64x2)\n","        target_batch = convert_target_to_one_hot(target_batch)\n","\n","        # Preprocess train batch\n","        x_batch -= 128.0\n","\n","        # Actually run one training step here\n","        _, cur_loss = ...\n","\n","        idx_start = idx_end\n","\n","        epoch_loss += cur_loss\n","    \n","    # Get summaries for the last batch\n","    summaries = ...\n","    train_writer.add_summary(summaries, epoch)\n","\n","    print('Epoch: {:03d} - Loss: {:.02f}'.format(epoch, epoch_loss / batches_each_epoch))\n"],"execution_count":0,"outputs":[]}]}