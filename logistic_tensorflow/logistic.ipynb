{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"logistic_pattern.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"znhXQsDuVTUS","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install googledrivedownloader\n","!pip install scikit-image --upgrade"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bwsKzAa_VUUZ","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","gdd.download_file_from_google_drive(file_id='1pzx_VdV_SwEgYnAZBQ0iZg0QDptA2UtO',dest_path='/tmp/X_img_train.npy',unzip=False)\n","gdd.download_file_from_google_drive(file_id='1SMvIaSEsiDgBDmk7IvtQObk7x7s2rRwx',dest_path='/tmp/X_feat_train.npy',unzip=False)\n","gdd.download_file_from_google_drive(file_id='1FbygsCk1g-Lq6TXX7y-CPZSGc7d04LSx',dest_path='/tmp/X_img_test.npy',unzip=False)\n","gdd.download_file_from_google_drive(file_id='1v_owXbovNXDz6EYSDgsgVH7VvQKF8Jwq',dest_path='/tmp/X_feat_test.npy',unzip=False)\n","gdd.download_file_from_google_drive(file_id='1s47YpYmZkH9l-u1sXHIWF51BYx9HjFBz',dest_path='/tmp/Y_test.npy',unzip=False)\n","gdd.download_file_from_google_drive(file_id='1vrnS0GbyQkQQUwyVY8TAzo_m0ESGxRWl',dest_path='/tmp/Y_train.npy',unzip=False)\n","\n","X_img_train, X_feat_train, Y_train, X_img_test, X_feat_test, Y_test = np.load('/tmp/X_img_train.npy'), np.load('/tmp/X_feat_train.npy'), np.load('/tmp/Y_train.npy'), np.load('/tmp/X_img_test.npy'), np.load('/tmp/X_feat_test.npy'), np.load('/tmp/Y_test.npy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6U2vSo9wVZZj","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"Img. shape: {0} - values in [{1},{2:.2f}]\".format(X_img_train.shape,np.min(X_img_train),np.max(X_img_train)))\n","print(\"Feature shape: {0} - values in [{1},{2:.2f}]\".format(X_feat_train.shape,np.min(X_feat_train),np.max(X_feat_train)))\n","print(\"Ground truth shape: {0} - classes: {1}\".format(Y_train.shape,np.unique(Y_train)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ketA3BijVkU5","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.subplot(121)\n","plt.title('Class 0. Non people')\n","X_0 = X_img_train[Y_train == 0.0]\n","random_idx_1 = np.random.choice(np.arange(0, X_0.shape[0]))\n","plt.imshow(X_0[random_idx_1], cmap='gray')\n","plt.grid(b=False)\n","\n","plt.subplot(122)\n","plt.title('Class 1. People')\n","X_1 = X_img_train[Y_train == 1.0]\n","random_idx_2 = np.random.choice(np.arange(0, X_1.shape[0]))\n","plt.imshow(X_1[random_idx_2], cmap='gray')\n","plt.grid(b=False)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3ycv5OunVsfk","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","\n","_, n_features = X_feat_train.shape\n","\n","# define placeholders and variables\n","X = # Define the placeholder for input samples.\n","Y = # Define the placeholder for the ground truth, in terms of one-hot encoding.\n","W = # Define the weight variable\n","b = # Define the bias variable"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oAGRGCcQiLa4","colab_type":"text"},"cell_type":"markdown","source":["# Do your stuffs"]},{"metadata":{"id":"rg--S3NRV0YO","colab_type":"code","colab":{}},"cell_type":"code","source":["def sigmoid(X):\n","  \"\"\"\n","    Code for the sigmoid function. https://en.wikipedia.org/wiki/Logistic_function\n","  \"\"\"\n","  pass\n","\n","def binary_crossentropy(y_true, y_pred):\n","  \"\"\"\n","    Code for the binary cross entropy. https://en.wikipedia.org/wiki/Cross_entropy\n","  \"\"\"\n","  pass\n","\n","def accuracy(y_true, y_pred):\n","  \"\"\"\n","  Given ground truth and prediction, compute the mean accuracy.\n","  \"\"\"\n","  pass\n","\n","def inference():\n","    \n","Z = None # Define Z as a linear trasformation over X, then apply the logistic activation function. \n","Z_0_1 = None # Define Z_0_1 as a binary value computed from Z\n","\n","loss = binary_crossentropy(y_true=Y, y_pred=Z)\n","acc = accuracy(y_true=Y, y_pred=Z_0_1)\n","\n","optimizer = None # Instantiate the algorithm for Gradient Descent\n","train_step = None # Given the optimizer and the loss, create an operation representing the training step. \n","\n","with tf.Session() as sess:\n","\n","    sess.run(tf.global_variables_initializer())\n","    \n","    NUM_EPOCHS = 100000\n","\n","    for i in range(0, NUM_EPOCHS):\n","      sess.run(train_step, feed_dict={X: X_feat_train, Y:Y_train})\n","      if i % 1000 == 0: \n","        train_loss, train_acc = sess.run([loss, acc], feed_dict={X: X_feat_train, Y:Y_train})   \n","        test_loss, test_acc = sess.run([loss, acc], feed_dict={X: X_feat_test, Y:Y_test})  \n","        Y_test_pred = sess.run(Z_0_1, feed_dict={X: X_feat_test, Y:Y_test})  \n","        print(\"Training Loss (CE) : {:0.2f}; Training acc. : {:0.2f}; Test Loss (CE) : {:0.2f} Test acc. : {:0.2f}; \".format(train_loss, train_acc, test_loss, test_acc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EWCzzBlzv8ta","colab_type":"code","colab":{}},"cell_type":"code","source":["labels = ['Non people', 'People']\n","num_row, num_col = 2, 6\n","f,subplots = plt.subplots(num_row, num_col, sharex='col', sharey='row')\n","\n","for i in range(num_row):\n","    for j in range(num_col):\n","        idx = np.random.choice(np.arange(0, X_img_test.shape[0]))\n","        subplots[i,j].imshow(X_img_test[idx], cmap='gray', interpolation='nearest', aspect='auto')\n","        title = 'GT: {} \\n Pred: {}'.format(labels[int(Y_test[idx])], labels[int(Y_test_pred[idx])])\n","        color_title = 'green' if int(Y_test[idx]) == int(Y_test_pred[idx]) else 'red'\n","        subplots[i,j].set_title(title, color=color_title, fontweight=\"bold\")\n","        subplots[i,j].grid(b=False)\n","\n","f.set_size_inches(13.5, 7.5)"],"execution_count":0,"outputs":[]}]}