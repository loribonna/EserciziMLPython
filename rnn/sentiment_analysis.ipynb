{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["kbzCKSN8yy-u"]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"NXRuQ8W9fZ7r","colab_type":"text"},"cell_type":"markdown","source":["Install proper packages"]},{"metadata":{"id":"PvQ8uv1rcbq7","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install googledrivedownloader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1EPel4HZfeZS","colab_type":"text"},"cell_type":"markdown","source":["Import proper packages and download tweets data"]},{"metadata":{"id":"_Qlx71SEbTmr","colab_type":"code","colab":{}},"cell_type":"code","source":["import re\n","import csv\n","import numpy as np\n","import tensorflow as tf\n","from collections import Counter\n","from google_drive_downloader import GoogleDriveDownloader\n","\n","\n","GoogleDriveDownloader.download_file_from_google_drive(file_id='1fHezNVY4YWJVWYb_3P3kx2e9RstjY1OK',\n","                                                      dest_path='data/tweets.zip',\n","                                                      unzip=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a-L430aWfpSL","colab_type":"text"},"cell_type":"markdown","source":["Global parameters, nothing fancy for now"]},{"metadata":{"id":"j6ennN7LcgC7","colab_type":"code","colab":{}},"cell_type":"code","source":["EPS = np.finfo('float32').eps       # machine precision for float32\n","MAX_TWEET_CHARS = 140               # each tweet is made by max. 140 characters"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g6FquVPOfyOk","colab_type":"text"},"cell_type":"markdown","source":["Data loading primitives, useful to load tweets and their annotation in a numerical representation"]},{"metadata":{"id":"KlVtVqdPcoAr","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess(line):\n","    \"\"\"\n","    Pre-process a string of text. Eventually add additional pre-processing here.\n","    \"\"\"\n","    line = line.lower()               # turn to lowercase\n","    line = line.replace('\\n', '')     # remove newlines\n","    line = re.sub(r'\\W+', ' ', line)  # keep characters only (\\W is short for [^\\w])\n","\n","    return line\n","\n","\n","def get_dictionary(filename, dict_size=2000):\n","    \"\"\"\n","    Read the tweets and return a list of the 'max_words' most common words.\n","    \"\"\"\n","    all_words = []\n","    with open(filename, 'r') as csv_file:\n","        r = csv.reader(csv_file, delimiter=',', quotechar='\"')\n","        for row in r:\n","            tweet = row[3]\n","            if len(tweet) <= MAX_TWEET_CHARS:\n","                words = preprocess(tweet).split()\n","                all_words += words\n","\n","    # Make the dictionary out of only the N most common words\n","    word_counter = Counter(all_words)\n","    dictionary, _ = zip(*word_counter.most_common(min(dict_size, len(word_counter))))\n","\n","    return dictionary\n","\n","\n","class TweetLoader(object):\n","\n","    def __init__(self, filename_train, filename_val, batchsize, max_len, dict_size):\n","\n","        self._filename_train = filename_train\n","        self._filename_val = filename_val\n","        self._batchsize = batchsize\n","        self._max_len = max_len\n","        self._dict_size = dict_size\n","\n","        # get the list of words that will constitute our dictionary (once only)\n","        self._dictionary = get_dictionary(self._filename_train, dict_size)\n","\n","        self._train_rows = self.read_data(self._filename_train)\n","        self._val_rows = self.read_data(self._filename_val)\n","\n","    def read_data(self, filename):\n","        # read training data\n","        rows = []\n","        with open(filename, 'r') as csv_file:\n","            reader = csv.reader(csv_file, delimiter=',', quotechar='\"')\n","            for row in reader:\n","                rows.append(row)\n","        return rows\n","\n","    def vectorize(self, tweet):\n","        words = preprocess(tweet).split()\n","\n","        X = np.zeros(shape=(1, self._max_len, self._dict_size + 1))\n","\n","        # Vectorization\n","        for j, w in enumerate(words):\n","            if j < self._max_len:\n","                try:\n","                    w_idx = self._dictionary.index(w)\n","                    X[0, j, w_idx + 1] = 1\n","                except ValueError:\n","                    # Word not found, using the unknown\n","                    X[0, j, 0] = 1\n","\n","        return X\n","\n","    def load_tweet_batch(self, mode):\n","        \"\"\"\n","        Generate a batch of training data\n","        \"\"\"\n","        assert mode in ['train', 'val']\n","        if mode == 'train':\n","            rows = self._train_rows\n","        else:\n","            rows = self._val_rows\n","\n","        # prepare data structures\n","        X_batch = np.zeros((self._batchsize, self._max_len, len(self._dictionary) + 1), dtype=np.float32)\n","        Y_batch = np.zeros((self._batchsize, 2), dtype=np.float32)\n","\n","        tweet_loaded = 0\n","        while tweet_loaded < self._batchsize:\n","\n","            rand_idx = np.random.randint(0, len(rows))\n","            Y_batch[tweet_loaded, int(rows[rand_idx][1])] = 1\n","\n","            random_tweet = rows[rand_idx][3]\n","            if len(random_tweet) <= MAX_TWEET_CHARS:\n","\n","                X = self.vectorize(tweet=random_tweet)\n","                X_batch[tweet_loaded] = X[0]\n","                tweet_loaded += 1\n","\n","        return X_batch, Y_batch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z5-7vG8tgr2V","colab_type":"text"},"cell_type":"markdown","source":["Define our recurrent model for sentiment analysis on tweets: the functions you have to implement are make_inference, make_loss, make_train_step."]},{"metadata":{"id":"4PkKrM3acrA7","colab_type":"code","colab":{}},"cell_type":"code","source":["def length(sequence):\n","    \"\"\"\n","    Returns the useful lenght of the sequence.\n","    \"\"\"\n","    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n","    length = tf.reduce_sum(used, 1)\n","    length = tf.cast(length, tf.int32)\n","    return length\n","\n","\n","def last_relevant(output, length):\n","    \"\"\"\n","    Returns the indexes of the last relevant element of the sequence.\n","    \"\"\"\n","    batch_size = tf.shape(output)[0]\n","    max_length = tf.shape(output)[1]\n","    out_size = int(output.get_shape()[2])\n","    index = tf.range(0, batch_size) * max_length + (length - 1)\n","    flat = tf.reshape(output, [-1, out_size])\n","    relevant = tf.gather(flat, index)\n","    return relevant\n","\n","\n","class TweetModel(object):\n","\n","    def __init__(self, x, targets, hidden_size):\n","\n","        self.x = x\n","        self.targets = targets\n","        self.n_classes = targets.get_shape()[-1]\n","\n","        self.hidden_size = hidden_size\n","\n","        self.inference = None\n","        self.loss = None\n","        self.train_step = None\n","        self.accuracy = None\n","\n","        self.make_inference()\n","        self.make_loss()\n","        self.make_train_step()\n","        self.make_accuracy()\n","\n","    def make_inference(self):\n","\n","        # Define the final prediction applying a fully connected layer with softmax\n","        self.inference = None\n","\n","    def make_loss(self):\n","        self.loss = None\n","\n","    def make_train_step(self):\n","        self.train_step = None\n","        \n","    def make_accuracy(self):\n","        self.accuracy = None\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kbzCKSN8yy-u","colab_type":"text"},"cell_type":"markdown","source":["#My solution"]},{"metadata":{"id":"ZJkLXnEqyws_","colab_type":"code","colab":{}},"cell_type":"code","source":["def length(sequence):\n","    \"\"\"\n","    Returns the useful lenght of the sequence.\n","    \"\"\"\n","    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n","    length = tf.reduce_sum(used, 1)\n","    length = tf.cast(length, tf.int32)\n","    return length\n","\n","\n","def last_relevant(output, length):\n","    \"\"\"\n","    Returns the indexes of the last relevant element of the sequence.\n","    \"\"\"\n","    batch_size = tf.shape(output)[0]\n","    max_length = tf.shape(output)[1]\n","    out_size = int(output.get_shape()[2])\n","    index = tf.range(0, batch_size) * max_length + (length - 1)\n","    flat = tf.reshape(output, [-1, out_size])\n","    relevant = tf.gather(flat, index)\n","    return relevant\n","\n","\n","class TweetModel(object):\n","\n","    def __init__(self, x, targets, hidden_size):\n","\n","        self.x = x\n","        self.targets = targets\n","        self.n_classes = targets.get_shape()[-1]\n","\n","        self.hidden_size = hidden_size\n","\n","        self.inference = None\n","        self.loss = None\n","        self.train_step = None\n","        self.accuracy = None\n","\n","        self.make_inference()\n","        self.make_loss()\n","        self.make_train_step()\n","        self.make_accuracy()\n","\n","    def make_inference(self):\n","\n","        # Create LSTM cell with proper hidden size\n","        cell = tf.contrib.rnn.LSTMCell(self.hidden_size)\n","\n","        # Get LSTM output\n","        val, state = tf.nn.dynamic_rnn(cell, self.x, sequence_length=length(self.x), dtype=tf.float32)\n","\n","        # Get last output of LSTM\n","        last = last_relevant(val, length(val))\n","\n","        # Define the final prediction applying a fully connected layer with softmax\n","        self.inference = tf.layers.dense(state[0], self.n_classes, activation=tf.nn.softmax)\n","\n","    def make_loss(self):\n","        self.loss = - tf.reduce_sum(self.targets * tf.log(self.inference + EPS))\n","\n","    def make_train_step(self):\n","        self.train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.loss)\n","\n","    def make_accuracy(self):\n","        mistakes = tf.equal(tf.argmax(self.inference, axis=1), tf.argmax(self.targets, axis=1))\n","        self.accuracy = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QURWTcdqy5eK","colab_type":"text"},"cell_type":"markdown","source":["#Training and Test"]},{"metadata":{"id":"SHCa5vwvhhnm","colab_type":"text"},"cell_type":"markdown","source":["Define some hyperparameters"]},{"metadata":{"id":"eJ266A-ccw3U","colab_type":"code","colab":{}},"cell_type":"code","source":["# Model parameters\n","max_seq_len = 20  # Maximum length (in words) of tweets\n","max_dict_size = 1000  # Maximum dictionary size\n","hidden_size = 10  # LSTM cell dimension\n","train_tweets_path = 'data/tweets_train.csv'\n","val_tweets_path = 'data/tweets_val.csv'\n","\n","# Training parameters\n","training_epochs = 20 # Number of training epochs\n","batch_size = 32 # Size of each training batch\n","batches_each_epoch = 500 # Number of batches for each epochs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8SwgLsVzhlaj","colab_type":"text"},"cell_type":"markdown","source":["Get the TweetLoader that will provide us training batches"]},{"metadata":{"id":"OPIeJRSLc2cT","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get tweet loader\n","loader = TweetLoader(train_tweets_path, val_tweets_path, batch_size, max_seq_len, max_dict_size)\n","x_batch, y_batch = loader.load_tweet_batch(mode='train')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TX9psE2nh2YL","colab_type":"text"},"cell_type":"markdown","source":["Define placeholders for tweets (x) and sentiments (target). Be extra-careful to shapes!"]},{"metadata":{"id":"g__dzm0Ec4WL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Declare placeholders\n","x = tf.placeholder(shape=(None, max_seq_len, max_dict_size+1), dtype=tf.float32)\n","targets = tf.placeholder(shape=(None, 2), dtype=tf.float32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eYJBeqwci0VE","colab_type":"text"},"cell_type":"markdown","source":["Instantiate the model."]},{"metadata":{"id":"H-piAaLXc-zr","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get a model\n","model = TweetModel(x, targets, hidden_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RdBoYw0-i22B","colab_type":"text"},"cell_type":"markdown","source":["Open tensorflow session..."]},{"metadata":{"id":"fazUWrTBdHsy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Open new session\n","sess = tf.Session()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5NGMGnR9i6ef","colab_type":"text"},"cell_type":"markdown","source":["... and initialize variables."]},{"metadata":{"id":"Ymf3WkYrdJyy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Initialize all variables\n","sess.run(tf.global_variables_initializer())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KwzCF6SHi-Bb","colab_type":"text"},"cell_type":"markdown","source":["Training loop, fill in blanks following comments"]},{"metadata":{"id":"akiG8n7bdQm8","colab_type":"code","colab":{}},"cell_type":"code","source":["for epoch in range(training_epochs):\n","\n","    x_batch, y_batch = loader.load_tweet_batch(mode='train')\n","    print('Epoch: {}\\tTRAIN: Loss: {:.02f} Accuracy: {:.02f}'.format(\n","        epoch,\n","        # Compute batch loss\n","        sess.run(model.loss, feed_dict={x: x_batch, targets: y_batch}),\n","        # Compute batch accuracy\n","        sess.run(model.accuracy, feed_dict={x: x_batch, targets: y_batch})\n","    ))\n","\n","    x_batch, y_batch = loader.load_tweet_batch(mode='val')\n","    print('Epoch: {}\\tVAL: Loss: {:.02f} Accuracy: {:.02f}'.format(\n","        epoch,\n","        # Compute batch loss\n","        sess.run(model.loss, feed_dict={x: x_batch, targets: y_batch}),\n","        # Compute batch accuracy\n","        sess.run(model.accuracy, feed_dict={x: x_batch, targets: y_batch})\n","    ))\n","\n","    for _ in range(batches_each_epoch):\n","\n","        # Load a batch of training data\n","        x_batch, y_batch = loader.load_tweet_batch(mode='train')\n","\n","        # Actually run one training step here\n","        sess.run(fetches=[model.train_step], feed_dict={x: x_batch, targets: y_batch})\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QdhnJo6jdSu6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Interactive session\n","while True:\n","    tw = raw_input('Try tweeting something!')\n","    if tw:\n","        x_num = loader.vectorize(tweet=tw)\n","        p, = sess.run([model.inference], feed_dict={x: x_num})\n","        if np.argmax(p) == 0:\n","            # Negative tweet\n","            print('Prediction:{}\\t:('.format(p))\n","        else:\n","            print('Prediction:{}\\t:)'.format(p))\n","    else:\n","        break\n"],"execution_count":0,"outputs":[]}]}